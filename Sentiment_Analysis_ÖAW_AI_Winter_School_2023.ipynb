{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CDL-RecSys/oeaw-ai-winter-school-2023/blob/main/Sentiment_Analysis_%C3%96AW_AI_Winter_School_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the Sentiment Analysis Tutorial!\n",
        "\n",
        "In this tutorial we will explore three of the major approaches of performing sentiment analysis by presenting a ...\n",
        "\n",
        "*   dictionary based approach ([VADER](https://ojs.aaai.org/index.php/ICWSM/article/view/14550)).\n",
        "*   machine learning (ML) based approach (which runs efficiently on a CPU) ([fastText](https://aclanthology.org/E17-2068/))\n",
        "*   machine learning (ML) based approach (which requires a GPU if used in production) ([BERT](https://aclanthology.org/N19-1423/))\n"
      ],
      "metadata": {
        "id": "4sb3p8Qwv7UE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dictionary Based Approach\n",
        "\n",
        "Dictionary-based approaches have played an important role in conducting sentiment analysis in the past. Nevertheless, they have advantages that make them important in the current state of the art (SOTA) as well. Important aspects here are, above all, that they are explainable and transparent. Current SOTA algorithms such as the BERT algorithm are not explainable.\n",
        "\n",
        "Explainability is not always a necessary requirement, but there are areas where one has to prove why a certain element is marked as positive, neutral or negative.\n",
        "\n",
        "---\n",
        "\n",
        "**Source**: *Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.*"
      ],
      "metadata": {
        "id": "5CubAtu5IQfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# execute this cell to install the vaderSentiment package\n",
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "6SuSKPoiv5l8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7379c96-cf85-4fca-b406-92e1755afd48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.8/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from vaderSentiment) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# source: https://github.com/cjhutto/vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# --- examples -------\n",
        "sentences = [\"VADER is smart, handsome, and funny.\",                      # positive sentence example\n",
        "             \"VADER is smart, handsome, and funny!\",                      # punctuation emphasis handled correctly (sentiment intensity adjusted)\n",
        "             \"VADER is very smart, handsome, and funny.\",                 # booster words handled correctly (sentiment intensity adjusted)\n",
        "             \"VADER is VERY SMART, handsome, and FUNNY.\",                 # emphasis for ALLCAPS handled\n",
        "             \"VADER is VERY SMART, handsome, and FUNNY!!!\",               # combination of signals - VADER appropriately adjusts intensity\n",
        "             \"VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!\",  # booster words & punctuation make this close to ceiling for score\n",
        "             \"VADER is not smart, handsome, nor funny.\",                  # negation sentence example\n",
        "             \"The book was good.\",                                        # positive sentence\n",
        "             \"At least it isn't a horrible book.\",                        # negated negative sentence with contraction\n",
        "             \"The book was only kind of good.\",                           # qualified positive sentence is handled correctly (intensity adjusted)\n",
        "             \"The plot was good, but the characters are uncompelling and the dialog is not great.\", # mixed negation sentence\n",
        "             \"Today SUX!\",                                                # negative slang with capitalization emphasis\n",
        "             \"Today only kinda sux! But I'll get by, lol\",                # mixed sentiment example with slang and constrastive conjunction \"but\"\n",
        "             \"Make sure you :) or :D today!\",                             # emoticons handled\n",
        "             \"Catch utf-8 emoji such as such as üíò and üíã and üòÅ\",        # emojis handled\n",
        "             \"Not bad at all\"                                             # Capitalized negation\n",
        "             ]\n",
        "\n",
        "analyzer_vader = SentimentIntensityAnalyzer()\n",
        "for sentence in sentences:\n",
        "    vs = analyzer_vader.polarity_scores(sentence)\n",
        "    print(\"{:-<65} {}\".format(sentence, str(vs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r629857QKT7q",
        "outputId": "23897589-a975-423c-844a-ad48d8f1e84b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VADER is smart, handsome, and funny.----------------------------- {'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}\n",
            "VADER is smart, handsome, and funny!----------------------------- {'neg': 0.0, 'neu': 0.248, 'pos': 0.752, 'compound': 0.8439}\n",
            "VADER is very smart, handsome, and funny.------------------------ {'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.8545}\n",
            "VADER is VERY SMART, handsome, and FUNNY.------------------------ {'neg': 0.0, 'neu': 0.246, 'pos': 0.754, 'compound': 0.9227}\n",
            "VADER is VERY SMART, handsome, and FUNNY!!!---------------------- {'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'compound': 0.9342}\n",
            "VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!--------- {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.9469}\n",
            "VADER is not smart, handsome, nor funny.------------------------- {'neg': 0.646, 'neu': 0.354, 'pos': 0.0, 'compound': -0.7424}\n",
            "The book was good.----------------------------------------------- {'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
            "At least it isn't a horrible book.------------------------------- {'neg': 0.0, 'neu': 0.678, 'pos': 0.322, 'compound': 0.431}\n",
            "The book was only kind of good.---------------------------------- {'neg': 0.0, 'neu': 0.697, 'pos': 0.303, 'compound': 0.3832}\n",
            "The plot was good, but the characters are uncompelling and the dialog is not great. {'neg': 0.327, 'neu': 0.579, 'pos': 0.094, 'compound': -0.7042}\n",
            "Today SUX!------------------------------------------------------- {'neg': 0.779, 'neu': 0.221, 'pos': 0.0, 'compound': -0.5461}\n",
            "Today only kinda sux! But I'll get by, lol----------------------- {'neg': 0.127, 'neu': 0.556, 'pos': 0.317, 'compound': 0.5249}\n",
            "Make sure you :) or :D today!------------------------------------ {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.8633}\n",
            "Catch utf-8 emoji such as such as üíò and üíã and üòÅ------------------ {'neg': 0.0, 'neu': 0.615, 'pos': 0.385, 'compound': 0.875}\n",
            "Not bad at all--------------------------------------------------- {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning Based Approach (fastText)\n",
        "\n",
        "The fastText framework is a machine learning approach which is optimized to run on standard hardware. It does not require a GPU for training or performing predictions. \n",
        "\n",
        "---\n",
        "\n",
        "**Source**: *Joulin, A., Grave, E., Bojanowski, P., & Mikolov, T. (2016). Bag of Tricks for Efficient Text Classification. arXiv preprint arXiv:1607.01759.*"
      ],
      "metadata": {
        "id": "nGTF3ywBKoDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the fasttext implementation\n",
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhc16lKXKwfJ",
        "outputId": "1acd4888-f473-4812-b595-f7dbc641d866"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.8/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.8/dist-packages (from fasttext) (2.10.3)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install datasets package\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T5Yym9E6kyF",
        "outputId": "cfbef852-4eef-450e-dd82-bbf641c46a4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now using the same data set which is also used by the BERT based model in the 3rd section of this tutorial ([tweet_eval](https://huggingface.co/datasets/tweet_eval)).\n",
        "\n",
        "The data set can be retrieved by using the \"datasets\" package of Hugging Face.\n",
        "\n",
        "---\n",
        "\n",
        "**Source:** \n",
        "\n",
        "*   *Barbieri, F., Camacho-Collados, J., Espinosa-Anke, L., & Neves, L. (2020). TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification. In Proceedings of Findings of EMNLP.*\n",
        "*   *Rosenthal, S., Farra, N., & Nakov, P. (2017). SemEval-2017 task 4: Sentiment analysis in Twitter. In Proceedings of the 11th international workshop on semantic evaluation (SemEval-2017) (pp. 502‚Äì518).*"
      ],
      "metadata": {
        "id": "-HQw3U0X4Z8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the same data set as the BERT based approach is using for training\n",
        "from datasets import get_dataset_config_names\n",
        "from datasets import get_dataset_split_names\n",
        "from datasets import load_dataset\n",
        "\n",
        "# retrieve the data set split names\n",
        "dataset_split_names = get_dataset_split_names(\"tweet_eval\",\"sentiment\")\n",
        "\n",
        "# retrieve da available options (could be different languages or data set sub-types)\n",
        "configs = get_dataset_config_names(\"tweet_eval\")\n",
        "\n",
        "print(dataset_split_names)\n",
        "print(configs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FeIqLCvLP35",
        "outputId": "5e8d05dd-02c2-487c-e1ff-80ef43a85797"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train', 'test', 'validation']\n",
            "['emoji', 'emotion', 'hate', 'irony', 'offensive', 'sentiment', 'stance_abortion', 'stance_atheism', 'stance_climate', 'stance_feminist', 'stance_hillary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print a preview of the data set structure (to get a grasp on the size of the used data set and the distribution over the splits)\n",
        "train_dataset = load_dataset(\"tweet_eval\", \"sentiment\",split=\"train\")\n",
        "test_dataset = load_dataset(\"tweet_eval\", \"sentiment\",split=\"test\")\n",
        "validation_dataset = load_dataset(\"tweet_eval\", \"sentiment\",split=\"validation\")\n",
        "print(train_dataset)\n",
        "print(test_dataset)\n",
        "print(validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwBIao3Z7Hko",
        "outputId": "3a3fcb39-1c30-4a95-8d15-a93715fdc29a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
            "WARNING:datasets.builder:Found cached dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
            "WARNING:datasets.builder:Found cached dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 45615\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 12284\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 2000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels within the data set:\n",
        "# 0: negative\n",
        "# 1: neutral\n",
        "# 2: positive\n",
        "\n",
        "print(train_dataset[0])           # print the line without formatting\n",
        "print('')\n",
        "print(train_dataset[0]['text'])   # text of the tweet only\n",
        "print(train_dataset[0]['label'])  # sentiment label of the tweet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yECDhzBg9Yrs",
        "outputId": "e8d12aaf-1f45-4684-d3a0-41a3d0b7dbd9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': '\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"', 'label': 2}\n",
            "\n",
            "\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-processing\n",
        "# source: https://fasttext.cc/docs/en/supervised-tutorial.html#getting-and-preparing-the-data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def adapt_label(df):\n",
        "  df.loc[df['label'] == 0, 'label'] = '__label__negative'\n",
        "  df.loc[df['label'] == 1, 'label'] = '__label__neutral'\n",
        "  df.loc[df['label'] == 2, 'label'] = '__label__positive'\n",
        "  df['combined'] = df['label']+\" \"+df['text']\n",
        "  return df\n",
        "\n",
        "df_train = pd.DataFrame(train_dataset)\n",
        "df_train = adapt_label(df_train)\n",
        "\n",
        "df_test= pd.DataFrame(test_dataset)\n",
        "df_test = adapt_label(df_test)\n",
        "\n",
        "df_valid = pd.DataFrame(validation_dataset)\n",
        "df_valid = adapt_label(df_valid)\n",
        "\n",
        "print(df_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDCoBIMI_fQO",
        "outputId": "c9f5105c-2d6e-4bce-8e48-1b0a47d81a35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    text              label  \\\n",
            "0      \"QT @user In the original draft of the 7th boo...  __label__positive   \n",
            "1      \"Ben Smith / Smith (concussion) remains out of...   __label__neutral   \n",
            "2      Sorry bout the stream last night I crashed out...   __label__neutral   \n",
            "3      Chase Headley's RBI double in the 8th inning o...   __label__neutral   \n",
            "4      @user Alciato: Bee will invest 150 million in ...  __label__positive   \n",
            "...                                                  ...                ...   \n",
            "45610  @user \\\"\"So amazing to have the beautiful Lady...  __label__positive   \n",
            "45611  9 September has arrived, which means Apple's n...  __label__positive   \n",
            "45612  Leeds 1-1 Sheff Wed. Giuseppe Bellusci securin...  __label__positive   \n",
            "45613  @user no I'm in hilton head till the 8th lol g...   __label__neutral   \n",
            "45614  WASHINGTON (Reuters) - U.S. Vice President Joe...   __label__neutral   \n",
            "\n",
            "                                                combined  \n",
            "0      __label__positive \"QT @user In the original dr...  \n",
            "1      __label__neutral \"Ben Smith / Smith (concussio...  \n",
            "2      __label__neutral Sorry bout the stream last ni...  \n",
            "3      __label__neutral Chase Headley's RBI double in...  \n",
            "4      __label__positive @user Alciato: Bee will inve...  \n",
            "...                                                  ...  \n",
            "45610  __label__positive @user \\\"\"So amazing to have ...  \n",
            "45611  __label__positive 9 September has arrived, whi...  \n",
            "45612  __label__positive Leeds 1-1 Sheff Wed. Giusepp...  \n",
            "45613  __label__neutral @user no I'm in hilton head t...  \n",
            "45614  __label__neutral WASHINGTON (Reuters) - U.S. V...  \n",
            "\n",
            "[45615 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts() # training data set class distribution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP8yFwj5GgZE",
        "outputId": "825ef554-3e93-4ced-81f5-a83bcaf52306"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__label__neutral     20673\n",
              "__label__positive    17849\n",
              "__label__negative     7093\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid['label'].value_counts() # validation data set class distribution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV1noosQPRBE",
        "outputId": "98389d7f-14fe-48e4-821a-886cb3ceaf0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__label__neutral     869\n",
              "__label__positive    819\n",
              "__label__negative    312\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[['label', 'text' ]].to_csv('df_train.txt', index=None, header=None)\n",
        "!cat df_train.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > df_train.preprocessed.txt\n",
        "\n",
        "df_valid[['label', 'text' ]].to_csv('df_valid.txt', index=None, header=None)\n",
        "!cat df_valid.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > df_valid.preprocessed.txt"
      ],
      "metadata": {
        "id": "rJRzZFnkKKUy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "model_fasttext_preprocessed = fasttext.train_supervised(input='df_train.preprocessed.txt',lr=1.0,epoch=25)"
      ],
      "metadata": {
        "id": "tvuUFMmmCZGE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fasttext_preprocessed.test(\"df_valid.preprocessed.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llDPxi9zOQHf",
        "outputId": "f439747c-4f8b-43db-9931-e389bab610ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 0.6485, 0.6485)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_fasttext_preprocessed.predict(\"FastText it's models fit well onto a mobile devices.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDqU8p8UQpRf",
        "outputId": "a18805f8-f648-479d-f021-fc84c933d787"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__positive',), array([0.98458219]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# source: https://github.com/cjhutto/vaderSentiment\n",
        "\n",
        "sentences = [\"VADER is smart, handsome, and funny.\",                      # positive sentence example\n",
        "             \"VADER is smart, handsome, and funny!\",                      # punctuation emphasis handled correctly (sentiment intensity adjusted)\n",
        "             \"VADER is very smart, handsome, and funny.\",                 # booster words handled correctly (sentiment intensity adjusted)\n",
        "             \"VADER is VERY SMART, handsome, and FUNNY.\",                 # emphasis for ALLCAPS handled\n",
        "             \"VADER is VERY SMART, handsome, and FUNNY!!!\",               # combination of signals - VADER appropriately adjusts intensity\n",
        "             \"VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!\",  # booster words & punctuation make this close to ceiling for score\n",
        "             \"VADER is not smart, handsome, nor funny.\",                  # negation sentence example\n",
        "             \"The book was good.\",                                        # positive sentence\n",
        "             \"At least it isn't a horrible book.\",                        # negated negative sentence with contraction\n",
        "             \"The book was only kind of good.\",                           # qualified positive sentence is handled correctly (intensity adjusted)\n",
        "             \"The plot was good, but the characters are uncompelling and the dialog is not great.\", # mixed negation sentence\n",
        "             \"Today SUX!\",                                                # negative slang with capitalization emphasis\n",
        "             \"Today only kinda sux! But I'll get by, lol\",                # mixed sentiment example with slang and constrastive conjunction \"but\"\n",
        "             \"Make sure you :) or :D today!\",                             # emoticons handled\n",
        "             \"Catch utf-8 emoji such as such as üíò and üíã and üòÅ\",        # emojis handled\n",
        "             \"Not bad at all\"                                             # Capitalized negation\n",
        "             ]\n",
        "\n",
        "with open('vader_sentences.txt','w') as tfile:\n",
        "\ttfile.write('\\n'.join(sentences))"
      ],
      "metadata": {
        "id": "v-8LwMSdSxKr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data pre-processing as suggested by fastText (https://fasttext.cc/docs/en/supervised-tutorial.html#preprocessing-the-data)\n",
        "!cat vader_sentences.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > vader_sentences.preprocessed.txt"
      ],
      "metadata": {
        "id": "uA_Gd8kF1lve"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# without preprocessing\n",
        "with open('vader_sentences.txt') as file:\n",
        "    for line in file:\n",
        "        vs = model_fasttext_preprocessed.predict(line.rstrip()) # to enable multi class prediction add \"k=3\"\n",
        "        print(\"{:-<65} {}\".format(line.rstrip(), str(vs))) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jblEv-MyVCNG",
        "outputId": "3af8327c-b09b-481f-d858-d7f2eecab6e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VADER is smart, handsome, and funny.----------------------------- (('__label__neutral',), array([1.00000787]))\n",
            "VADER is smart, handsome, and funny!----------------------------- (('__label__neutral',), array([1.00000787]))\n",
            "VADER is very smart, handsome, and funny.------------------------ (('__label__neutral',), array([0.96613878]))\n",
            "VADER is VERY SMART, handsome, and FUNNY.------------------------ (('__label__neutral',), array([1.00000787]))\n",
            "VADER is VERY SMART, handsome, and FUNNY!!!---------------------- (('__label__neutral',), array([1.00000787]))\n",
            "VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!--------- (('__label__neutral',), array([0.99969792]))\n",
            "VADER is not smart, handsome, nor funny.------------------------- (('__label__neutral',), array([0.98700446]))\n",
            "The book was good.----------------------------------------------- (('__label__neutral',), array([1.00001001]))\n",
            "At least it isn't a horrible book.------------------------------- (('__label__negative',), array([1.00001001]))\n",
            "The book was only kind of good.---------------------------------- (('__label__neutral',), array([0.94640237]))\n",
            "The plot was good, but the characters are uncompelling and the dialog is not great. (('__label__negative',), array([0.99985325]))\n",
            "Today SUX!------------------------------------------------------- (('__label__neutral',), array([1.00001001]))\n",
            "Today only kinda sux! But I'll get by, lol----------------------- (('__label__neutral',), array([0.9503811]))\n",
            "Make sure you :) or :D today!------------------------------------ (('__label__neutral',), array([1.00000978]))\n",
            "Catch utf-8 emoji such as such as üíò and üíã and üòÅ------------------ (('__label__positive',), array([0.9999733]))\n",
            "Not bad at all--------------------------------------------------- (('__label__negative',), array([0.64797509]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with preprocessing\n",
        "with open('vader_sentences.preprocessed.txt') as file:\n",
        "    for line in file:\n",
        "        vs = model_fasttext_preprocessed.predict(line.rstrip()) # to enable multi class prediction add \"k=3\"\n",
        "        print(\"{:-<65} {}\".format(line.rstrip(), str(vs))) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRUpI_mSTeE4",
        "outputId": "685baf16-82fc-4678-e7f2-2ed2671e64ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vader is smart ,  handsome ,  and funny .------------------------ (('__label__positive',), array([1.00001001]))\n",
            "vader is smart ,  handsome ,  and funny !------------------------ (('__label__positive',), array([1.00001001]))\n",
            "vader is very smart ,  handsome ,  and funny .------------------- (('__label__positive',), array([1.00001001]))\n",
            "vader is very smart ,  handsome ,  and funny .------------------- (('__label__positive',), array([1.00001001]))\n",
            "vader is very smart ,  handsome ,  and funny !  !  !------------- (('__label__positive',), array([1.00001001]))\n",
            "vader is very smart ,  uber handsome ,  and friggin funny !  !  ! (('__label__positive',), array([1.00001001]))\n",
            "vader is not smart ,  handsome ,  nor funny .-------------------- (('__label__positive',), array([1.00000989]))\n",
            "the book was good .---------------------------------------------- (('__label__positive',), array([0.99838203]))\n",
            "at least it isn ' t a horrible book .---------------------------- (('__label__negative',), array([1.00000989]))\n",
            "the book was only kind of good .--------------------------------- (('__label__positive',), array([0.99825048]))\n",
            "the plot was good ,  but the characters are uncompelling and the dialog is not great . (('__label__positive',), array([0.55338979]))\n",
            "today sux !------------------------------------------------------ (('__label__neutral',), array([0.99961966]))\n",
            "today only kinda sux !  but i ' ll get by ,  lol----------------- (('__label__neutral',), array([0.60178018]))\n",
            "make sure you : )  or :d today !--------------------------------- (('__label__positive',), array([0.99943495]))\n",
            "catch utf-8 emoji such as such as üíò and üíã and üòÅ------------------ (('__label__positive',), array([0.99998653]))\n",
            "not bad at all--------------------------------------------------- (('__label__negative',), array([0.99997604]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning Based Approach (BERT)"
      ],
      "metadata": {
        "id": "F0CBlAXbLQM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Link to the used model: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\n",
        "*   Repository: https://github.com/cardiffnlp/timelms\n",
        "*   This model is also integrated into the TweetNLP platform (https://tweetnlp.org/)\n",
        "\n",
        "---\n",
        "\n",
        "**Source:** *Daniel Loureiro, Francesco Barbieri, Leonardo Neves, Luis Espinosa Anke, and Jose Camacho-collados. 2022. TimeLMs: Diachronic Language Models from Twitter. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 251‚Äì260, Dublin, Ireland. Association for Computational Linguistics.*"
      ],
      "metadata": {
        "id": "ypge371DL8sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the transformers package to use Hugging Face models\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbnXIuLLLTGV",
        "outputId": "b2f99156-b6d4-4245-afe3-ff62ca482967"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# source: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "# pre-process text (username and link placeholders)\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)\n",
        "\n",
        "# load the choosen model\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)\n",
        "\n",
        "# pt\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "#model.save_pretrained(MODEL)\n",
        "\n",
        "def predict_bert(text):\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  list_predicted_labels = []\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = config.id2label[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      label = str(l) + \" \" + str(np.round(float(s), 4))\n",
        "      #print(label)\n",
        "      list_predicted_labels.append(label)\n",
        "  return(list_predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4S6yPgTPs7i",
        "outputId": "2696e8ae-e460-4f48-9ca4-09ac59f44bef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now use the same sentences from before and make use of the BERT model. It can be seen that the performance of this pre-trained BERT model is very good."
      ],
      "metadata": {
        "id": "IHWwekx_5-mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('vader_sentences.txt') as file:\n",
        "    for line in file:\n",
        "        vs = predict_bert(line.rstrip()) # to enable multi class prediction add \"k=3\"\n",
        "        print(\"{:-<65} {}\".format(line.rstrip(), str(vs))) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE4BTbd3VjKZ",
        "outputId": "4247c6b0-2e61-4fb7-f8a4-5913a111aacc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VADER is smart, handsome, and funny.----------------------------- ['positive 0.9637', 'neutral 0.0318', 'negative 0.0045']\n",
            "VADER is smart, handsome, and funny!----------------------------- ['positive 0.9789', 'neutral 0.018', 'negative 0.0031']\n",
            "VADER is very smart, handsome, and funny.------------------------ ['positive 0.9714', 'neutral 0.0248', 'negative 0.0037']\n",
            "VADER is VERY SMART, handsome, and FUNNY.------------------------ ['positive 0.9746', 'neutral 0.0206', 'negative 0.0048']\n",
            "VADER is VERY SMART, handsome, and FUNNY!!!---------------------- ['positive 0.9841', 'neutral 0.012', 'negative 0.0039']\n",
            "VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!--------- ['positive 0.9827', 'neutral 0.0126', 'negative 0.0047']\n",
            "VADER is not smart, handsome, nor funny.------------------------- ['negative 0.8702', 'neutral 0.1115', 'positive 0.0183']\n",
            "The book was good.----------------------------------------------- ['positive 0.9514', 'neutral 0.0441', 'negative 0.0044']\n",
            "At least it isn't a horrible book.------------------------------- ['negative 0.7535', 'neutral 0.2094', 'positive 0.0371']\n",
            "The book was only kind of good.---------------------------------- ['positive 0.6621', 'neutral 0.2985', 'negative 0.0393']\n",
            "The plot was good, but the characters are uncompelling and the dialog is not great. ['negative 0.7994', 'neutral 0.1732', 'positive 0.0274']\n",
            "Today SUX!------------------------------------------------------- ['neutral 0.6503', 'positive 0.3425', 'negative 0.0072']\n",
            "Today only kinda sux! But I'll get by, lol----------------------- ['negative 0.6094', 'neutral 0.2573', 'positive 0.1332']\n",
            "Make sure you :) or :D today!------------------------------------ ['positive 0.9404', 'neutral 0.057', 'negative 0.0026']\n",
            "Catch utf-8 emoji such as such as üíò and üíã and üòÅ------------------ ['neutral 0.7378', 'positive 0.2528', 'negative 0.0095']\n",
            "Not bad at all--------------------------------------------------- ['positive 0.8068', 'neutral 0.1686', 'negative 0.0247']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now it's your time to try out some sentences of your choice against the three different methods!\n",
        "\n",
        "Use the next code block to try out different sentences. Which approach do you like most?\n",
        "\n",
        "Try to improve the performance by pre-processing the input data. In addition you can try to tune the predictions by adapting the parameters during training."
      ],
      "metadata": {
        "id": "MxiT8wrrYeya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can try to pre-process the input data to increase the performance of the algorithms.\n",
        "# Information regarding pre-processing is available on the documentation sites for each of the algorithms.\n",
        "\n",
        "sentence = \"This is not bad!\"\n",
        "# Vader\n",
        "print(\"{:-<65} {}\".format(\"VADER: \"+sentence, analyzer_vader.polarity_scores(sentence.rstrip())))\n",
        "# fastText\n",
        "print(\"{:-<65} {}\".format(\"fastText: \"+sentence, str(model_fasttext_preprocessed.predict(sentence.rstrip())))) # to enable multi class prediction add \"k=3\"\n",
        "# BERT - to enable multi class prediction add \"k=3\"\n",
        "print(\"{:-<65} {}\".format(\"BERT: \"+sentence, str(predict_bert(sentence.rstrip())))) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDSlpIOEYvDk",
        "outputId": "e948583c-9e9d-44d3-a069-f4803366a565"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VADER: This is not bad!------------------------------------------ {'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.484}\n",
            "fastText: This is not bad!--------------------------------------- (('__label__neutral',), array([0.89596003]))\n",
            "BERT: This is not bad!------------------------------------------- ['positive 0.851', 'neutral 0.1321', 'negative 0.0169']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}